#!/usr/bin/env python
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ³Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø±ÙˆØ¬ÛŒ generate_tool_documents_for_rag

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª:
1. Ù…Ø³ØªÙ†Ø¯Ø§Øª RAG Ø±Ø§ Ø§Ø² tools ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
2. Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Documents Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
3. Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Documents Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
4. Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± RAG pipeline Ø±Ø§ ØªØ³Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import os
import sys
import json
from pathlib import Path

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ sys.path (Ù‡Ù…Ø§Ù† Ø±ÙˆØ´ schema_tool_generator.py)
project_root = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(project_root))

# Ø¯Ø±ÛŒØ§ÙØª settings module Ø§Ø² environment ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾ÛŒØ´â€ŒÙØ±Ø¶
settings_module = os.environ.get('DJANGO_SETTINGS_MODULE')
if not settings_module:
    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† settings module
    if (project_root / 'construction_project' / 'settings.py').exists():
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'construction_project.settings')
    else:
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† settings.py
        for settings_file in project_root.rglob('settings.py'):
            relative_path = settings_file.relative_to(project_root)
            module_path = str(relative_path).replace('/', '.').replace('\\', '.').replace('.py', '')
            os.environ.setdefault('DJANGO_SETTINGS_MODULE', module_path)
            break

try:
    import django
    django.setup()
except Exception as e:
    print(f"âš ï¸  Warning: Django setup failed: {e}")
    print("   Continuing without Django setup...")

from assistant.generators.schema_tool_generator import SchemaToolGenerator


def validate_document_structure(doc: dict) -> tuple[bool, list]:
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Document
    
    Returns:
        (is_valid, errors)
    """
    errors = []
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ page_content
    if 'page_content' not in doc:
        errors.append("âŒ page_content missing")
    elif not doc['page_content']:
        errors.append("âŒ page_content is empty")
    elif len(doc['page_content']) < 50:
        errors.append(f"âš ï¸  page_content too short ({len(doc['page_content'])} chars)")
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ metadata
    if 'metadata' not in doc:
        errors.append("âŒ metadata missing")
    else:
        metadata = doc['metadata']
        required_fields = ['tool_name', 'category', 'method', 'path']
        for field in required_fields:
            if field not in metadata:
                errors.append(f"âŒ metadata.{field} missing")
    
    return len(errors) == 0, errors


def analyze_document_content(doc: dict) -> dict:
    """ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Document"""
    page_content = doc.get('page_content', '')
    metadata = doc.get('metadata', {})
    
    analysis = {
        'tool_name': metadata.get('tool_name', 'unknown'),
        'content_length': len(page_content),
        'has_description': 'Description:' in page_content,
        'has_capabilities': 'Ù‚Ø§Ø¨Ù„ÛŒØª' in page_content or 'Capabilities' in page_content,
        'has_use_cases': 'Ø³Ù†Ø§Ø±ÛŒÙˆ' in page_content or 'Use Cases' in page_content,
        'has_parameters': 'Ù¾Ø§Ø±Ø§Ù…ØªØ±' in page_content or 'Parameters' in page_content,
        'has_examples': 'Ù…Ø«Ø§Ù„' in page_content or 'Examples' in page_content,
        'has_notes': 'Ù†Ú©Ø§Øª' in page_content or 'Notes' in page_content,
        'has_endpoint': 'API Endpoint:' in page_content,
        'parameter_count': len(metadata.get('parameters', [])),
        'category': metadata.get('category', 'unknown'),
        'method': metadata.get('method', 'unknown'),
    }
    
    return analysis


def print_document_sample(doc: dict, index: int = 0):
    """Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ Document"""
    print("\n" + "="*80)
    print(f"ğŸ“„ Ù†Ù…ÙˆÙ†Ù‡ Document #{index + 1}")
    print("="*80)
    
    metadata = doc.get('metadata', {})
    print(f"\nğŸ”§ Tool: {metadata.get('tool_name', 'unknown')}")
    print(f"ğŸ“ Category: {metadata.get('category', 'unknown')}")
    print(f"ğŸŒ Method: {metadata.get('method', 'unknown')}")
    print(f"ğŸ“ Path: {metadata.get('path', 'unknown')}")
    print(f"ğŸ·ï¸  Tags: {', '.join(metadata.get('tags', []))}")
    print(f"ğŸ” Auth Required: {metadata.get('has_auth', False)}")
    print(f"ğŸ“Š Parameters: {len(metadata.get('parameters', []))}")
    
    page_content = doc.get('page_content', '')
    print(f"\nğŸ“ Content Length: {len(page_content)} characters")
    print(f"\nğŸ“„ Content Preview (first 500 chars):")
    print("-" * 80)
    print(page_content[:500] + "..." if len(page_content) > 500 else page_content)
    print("-" * 80)


def test_rag_documents_generation():
    """ØªØ³Øª Ø§ØµÙ„ÛŒ ØªÙˆÙ„ÛŒØ¯ Documents"""
    print("ğŸ§ª ØªØ³Øª ØªÙˆÙ„ÛŒØ¯ Ù…Ø³ØªÙ†Ø¯Ø§Øª RAG Ø§Ø² Tools")
    print("="*80)
    
    # Ø§ÛŒØ¬Ø§Ø¯ generator
    print("\n1ï¸âƒ£  Ø§ÛŒØ¬Ø§Ø¯ SchemaToolGenerator...")
    try:
        generator = SchemaToolGenerator()
        print("   âœ… Generator Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ generator: {e}")
        return False
    
    # ØªÙˆÙ„ÛŒØ¯ Documents
    print("\n2ï¸âƒ£  ØªÙˆÙ„ÛŒØ¯ Documents Ø§Ø² Tools...")
    try:
        output_file = project_root / 'assistant' / 'generated' / 'test_tool_documents.json'
        documents = generator.generate_tool_documents_for_rag(str(output_file))
        print(f"   âœ… {len(documents)} Document ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Documents: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø±
    print("\n3ï¸âƒ£  Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Documents...")
    validation_results = []
    for i, doc in enumerate(documents):
        is_valid, errors = validate_document_structure(doc)
        validation_results.append((is_valid, errors))
        if not is_valid:
            print(f"   âš ï¸  Document #{i+1} ({doc.get('metadata', {}).get('tool_name', 'unknown')}):")
            for error in errors:
                print(f"      {error}")
    
    valid_count = sum(1 for is_valid, _ in validation_results if is_valid)
    print(f"   âœ… {valid_count}/{len(documents)} Documents Ù…Ø¹ØªØ¨Ø±")
    
    # ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§
    print("\n4ï¸âƒ£  ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Documents...")
    analyses = [analyze_document_content(doc) for doc in documents]
    
    # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
    avg_length = sum(a['content_length'] for a in analyses) / len(analyses) if analyses else 0
    has_all_sections = sum(
        1 for a in analyses 
        if a['has_description'] and a['has_parameters'] and a['has_examples']
    )
    
    print(f"   ğŸ“Š Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§: {avg_length:.0f} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    print(f"   ğŸ“Š Documents Ø¨Ø§ ØªÙ…Ø§Ù… Ø¨Ø®Ø´â€ŒÙ‡Ø§: {has_all_sections}/{len(analyses)}")
    
    # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
    categories = {}
    for a in analyses:
        cat = a['category']
        categories[cat] = categories.get(cat, 0) + 1
    
    print(f"\n   ğŸ“ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Documents:")
    for cat, count in sorted(categories.items()):
        print(f"      - {cat}: {count} tool")
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§
    print("\n5ï¸âƒ£  Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ Documents...")
    
    # Ù†Ù…ÙˆÙ†Ù‡ Ø§ÙˆÙ„: Ø§ÙˆÙ„ÛŒÙ† tool
    if documents:
        print_document_sample(documents[0], 0)
    
    # Ù†Ù…ÙˆÙ†Ù‡ Ø¯ÙˆÙ…: ÛŒÚ© tool Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù…Ø­ØªÙˆØ§
    if len(documents) > 1:
        max_content_doc = max(documents, key=lambda d: len(d.get('page_content', '')))
        max_index = documents.index(max_content_doc)
        print_document_sample(max_content_doc, max_index)
    
    # Ù†Ù…ÙˆÙ†Ù‡ Ø³ÙˆÙ…: ÛŒÚ© tool Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø®ØªÙ„Ù
    if len(documents) > 2:
        first_category = analyses[0]['category']
        different_doc = next(
            (doc for doc, a in zip(documents, analyses) if a['category'] != first_category),
            None
        )
        if different_doc:
            diff_index = documents.index(different_doc)
            print_document_sample(different_doc, diff_index)
    
    # ØªØ³Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø§ÛŒ LangChain
    print("\n6ï¸âƒ£  ØªØ³Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø§ÛŒ LangChain...")
    try:
        from langchain_core.documents import Document
        
        langchain_docs = [
            Document(page_content=doc['page_content'], metadata=doc['metadata'])
            for doc in documents[:5]  # ÙÙ‚Ø· 5 Ù…ÙˆØ±Ø¯ Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
        ]
        
        print(f"   âœ… {len(langchain_docs)} Document Ø¨Ù‡ ÙØ±Ù…Øª LangChain ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯")
        print(f"   âœ… Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± RAG pipeline")
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ LangChain Document
        if langchain_docs:
            print(f"\n   ğŸ“„ Ù†Ù…ÙˆÙ†Ù‡ LangChain Document:")
            print(f"      - page_content length: {len(langchain_docs[0].page_content)}")
            print(f"      - metadata keys: {list(langchain_docs[0].metadata.keys())}")
        
    except ImportError:
        print("   âš ï¸  langchain-core Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª (Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ú©Ø§Ù…Ù„ Ù†ÛŒØ§Ø² Ø§Ø³Øª)")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ LangChain Document: {e}")
    
    # Ø®Ù„Ø§ØµÙ‡
    print("\n" + "="*80)
    print("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
    print("="*80)
    print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Documents: {len(documents)}")
    print(f"âœ… Documents Ù…Ø¹ØªØ¨Ø±: {valid_count}/{len(documents)}")
    print(f"âœ… Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§: {avg_length:.0f} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    print(f"âœ… ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}")
    print(f"âœ… Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± RAG pipeline")
    
    # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
    print("\nğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:")
    if avg_length < 300:
        print("   âš ï¸  Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§ Ú©Ù… Ø§Ø³Øª. Ø¨Ù‡ØªØ± Ø§Ø³Øª ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø± ViewSets Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆØ¯.")
    if has_all_sections < len(analyses) * 0.8:
        print("   âš ï¸  Ø¨Ø±Ø®ÛŒ Documents Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ù†Ø¯Ø§Ø±Ù†Ø¯. docstring Ù‡Ø§ÛŒ ViewSets Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.")
    if valid_count < len(documents):
        print("   âš ï¸  Ø¨Ø±Ø®ÛŒ Documents Ø³Ø§Ø®ØªØ§Ø± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¯Ø§Ø±Ù†Ø¯. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    
    print("\nâœ… ØªØ³Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
    return True


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    try:
        success = test_rag_documents_generation()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ØªØ³Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
