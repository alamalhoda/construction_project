"""
Django management command Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù…Ø³ØªÙ†Ø¯Ø§Øª RAG

Ø§Ø³ØªÙØ§Ø¯Ù‡:
    python manage.py test_rag_documents
    python manage.py test_rag_documents --output test_output.json
"""

from django.core.management.base import BaseCommand
from assistant.generators.schema_tool_generator import SchemaToolGenerator
from django.conf import settings
import json
from pathlib import Path


class Command(BaseCommand):
    help = 'ØªØ³Øª ØªÙˆÙ„ÛŒØ¯ Ù…Ø³ØªÙ†Ø¯Ø§Øª RAG Ø§Ø² Tools Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Documents'

    def add_arguments(self, parser):
        parser.add_argument(
            '--output',
            type=str,
            default=None,
            help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ JSON Ø®Ø±ÙˆØ¬ÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: assistant/generated/test_tool_documents.json)',
        )
        parser.add_argument(
            '--sample',
            type=int,
            default=3,
            help='ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Documents Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 3)',
        )
        parser.add_argument(
            '--verbose',
            action='store_true',
            help='Ù†Ù…Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±',
        )

    def handle(self, *args, **options):
        output_file = options.get('output')
        sample_count = options.get('sample', 3)
        verbose = options.get('verbose', False)
        
        if not output_file:
            output_file = str(Path(settings.BASE_DIR) / 'assistant' / 'generated' / 'test_tool_documents.json')
        
        self.stdout.write(self.style.SUCCESS('ğŸ§ª ØªØ³Øª ØªÙˆÙ„ÛŒØ¯ Ù…Ø³ØªÙ†Ø¯Ø§Øª RAG Ø§Ø² Tools'))
        self.stdout.write('='*80)
        
        # Ø§ÛŒØ¬Ø§Ø¯ generator
        self.stdout.write('\n1ï¸âƒ£  Ø§ÛŒØ¬Ø§Ø¯ SchemaToolGenerator...')
        try:
            generator = SchemaToolGenerator()
            self.stdout.write(self.style.SUCCESS('   âœ… Generator Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯'))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'   âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ generator: {e}'))
            return
        
        # ØªÙˆÙ„ÛŒØ¯ Documents
        self.stdout.write('\n2ï¸âƒ£  ØªÙˆÙ„ÛŒØ¯ Documents Ø§Ø² Tools...')
        try:
            documents = generator.generate_tool_documents_for_rag(output_file)
            self.stdout.write(self.style.SUCCESS(f'   âœ… {len(documents)} Document ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯'))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'   âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Documents: {e}'))
            import traceback
            self.stdout.write(traceback.format_exc())
            return
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø±
        self.stdout.write('\n3ï¸âƒ£  Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± Documents...')
        valid_count = 0
        for i, doc in enumerate(documents):
            metadata = doc.get('metadata', {})
            tool_name = metadata.get('tool_name', 'unknown')
            
            # Ø¨Ø±Ø±Ø³ÛŒ page_content
            if 'page_content' not in doc or not doc['page_content']:
                self.stdout.write(self.style.WARNING(f'   âš ï¸  Document #{i+1} ({tool_name}): page_content missing'))
                continue
            
            # Ø¨Ø±Ø±Ø³ÛŒ metadata
            if 'metadata' not in doc:
                self.stdout.write(self.style.WARNING(f'   âš ï¸  Document #{i+1} ({tool_name}): metadata missing'))
                continue
            
            required_fields = ['tool_name', 'category', 'method', 'path']
            missing_fields = [f for f in required_fields if f not in doc['metadata']]
            if missing_fields:
                self.stdout.write(self.style.WARNING(f'   âš ï¸  Document #{i+1} ({tool_name}): missing fields: {missing_fields}'))
                continue
            
            valid_count += 1
        
        self.stdout.write(self.style.SUCCESS(f'   âœ… {valid_count}/{len(documents)} Documents Ù…Ø¹ØªØ¨Ø±'))
        
        # ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§
        self.stdout.write('\n4ï¸âƒ£  ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Documents...')
        analyses = []
        for doc in documents:
            page_content = doc.get('page_content', '')
            metadata = doc.get('metadata', {})
            
            analysis = {
                'tool_name': metadata.get('tool_name', 'unknown'),
                'content_length': len(page_content),
                'has_description': 'Description:' in page_content,
                'has_capabilities': 'Ù‚Ø§Ø¨Ù„ÛŒØª' in page_content or 'Capabilities' in page_content,
                'has_use_cases': 'Ø³Ù†Ø§Ø±ÛŒÙˆ' in page_content or 'Use Cases' in page_content,
                'has_parameters': 'Ù¾Ø§Ø±Ø§Ù…ØªØ±' in page_content or 'Parameters' in page_content,
                'has_examples': 'Ù…Ø«Ø§Ù„' in page_content or 'Examples' in page_content,
                'has_notes': 'Ù†Ú©Ø§Øª' in page_content or 'Notes' in page_content,
                'has_endpoint': 'API Endpoint:' in page_content,
                'parameter_count': len(metadata.get('parameters', [])),
                'category': metadata.get('category', 'unknown'),
            }
            analyses.append(analysis)
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        avg_length = sum(a['content_length'] for a in analyses) / len(analyses) if analyses else 0
        has_all_sections = sum(
            1 for a in analyses 
            if a['has_description'] and a['has_parameters'] and a['has_examples']
        )
        
        self.stdout.write(f'   ğŸ“Š Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§: {avg_length:.0f} Ú©Ø§Ø±Ø§Ú©ØªØ±')
        self.stdout.write(f'   ğŸ“Š Documents Ø¨Ø§ ØªÙ…Ø§Ù… Ø¨Ø®Ø´â€ŒÙ‡Ø§: {has_all_sections}/{len(analyses)}')
        
        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
        categories = {}
        for a in analyses:
            cat = a['category']
            categories[cat] = categories.get(cat, 0) + 1
        
        self.stdout.write(f'\n   ğŸ“ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Documents:')
        for cat, count in sorted(categories.items()):
            self.stdout.write(f'      - {cat}: {count} tool')
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§
        if sample_count > 0:
            self.stdout.write(f'\n5ï¸âƒ£  Ù†Ù…Ø§ÛŒØ´ {sample_count} Ù†Ù…ÙˆÙ†Ù‡ Document...')
            
            for i in range(min(sample_count, len(documents))):
                doc = documents[i]
                metadata = doc.get('metadata', {})
                page_content = doc.get('page_content', '')
                
                self.stdout.write('\n' + '-'*80)
                self.stdout.write(f'ğŸ“„ Ù†Ù…ÙˆÙ†Ù‡ Document #{i+1}')
                self.stdout.write('-'*80)
                self.stdout.write(f'ğŸ”§ Tool: {metadata.get("tool_name", "unknown")}')
                self.stdout.write(f'ğŸ“ Category: {metadata.get("category", "unknown")}')
                self.stdout.write(f'ğŸŒ Method: {metadata.get("method", "unknown")}')
                self.stdout.write(f'ğŸ“ Path: {metadata.get("path", "unknown")}')
                self.stdout.write(f'ğŸ“Š Parameters: {len(metadata.get("parameters", []))}')
                self.stdout.write(f'ğŸ“ Content Length: {len(page_content)} characters')
                
                if verbose:
                    self.stdout.write(f'\nğŸ“„ Content Preview (first 500 chars):')
                    self.stdout.write('-'*80)
                    preview = page_content[:500] + "..." if len(page_content) > 500 else page_content
                    self.stdout.write(preview)
                    self.stdout.write('-'*80)
        
        # ØªØ³Øª LangChain
        self.stdout.write('\n6ï¸âƒ£  ØªØ³Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø§ÛŒ LangChain...')
        try:
            from langchain_core.documents import Document
            
            langchain_docs = [
                Document(page_content=doc['page_content'], metadata=doc['metadata'])
                for doc in documents[:5]
            ]
            
            self.stdout.write(self.style.SUCCESS(f'   âœ… {len(langchain_docs)} Document Ø¨Ù‡ ÙØ±Ù…Øª LangChain ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯'))
            self.stdout.write(self.style.SUCCESS('   âœ… Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± RAG pipeline'))
            
        except ImportError:
            self.stdout.write(self.style.WARNING('   âš ï¸  langchain-core Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª'))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'   âŒ Ø®Ø·Ø§: {e}'))
        
        # Ø®Ù„Ø§ØµÙ‡
        self.stdout.write('\n' + '='*80)
        self.stdout.write(self.style.SUCCESS('ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:'))
        self.stdout.write('='*80)
        self.stdout.write(f'âœ… ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Documents: {len(documents)}')
        self.stdout.write(f'âœ… Documents Ù…Ø¹ØªØ¨Ø±: {valid_count}/{len(documents)}')
        self.stdout.write(f'âœ… Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§: {avg_length:.0f} Ú©Ø§Ø±Ø§Ú©ØªØ±')
        self.stdout.write(f'âœ… ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ: {output_file}')
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
        self.stdout.write('\nğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:')
        if avg_length < 300:
            self.stdout.write(self.style.WARNING('   âš ï¸  Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§ Ú©Ù… Ø§Ø³Øª. Ø¨Ù‡ØªØ± Ø§Ø³Øª ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø± ViewSets Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆØ¯.'))
        if has_all_sections < len(analyses) * 0.8:
            self.stdout.write(self.style.WARNING('   âš ï¸  Ø¨Ø±Ø®ÛŒ Documents Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ù†Ø¯Ø§Ø±Ù†Ø¯. docstring Ù‡Ø§ÛŒ ViewSets Ø±Ø§ ØªÚ©Ù…ÛŒÙ„ Ú©Ù†ÛŒØ¯.'))
        if valid_count < len(documents):
            self.stdout.write(self.style.WARNING('   âš ï¸  Ø¨Ø±Ø®ÛŒ Documents Ø³Ø§Ø®ØªØ§Ø± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¯Ø§Ø±Ù†Ø¯. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.'))
        
        self.stdout.write(self.style.SUCCESS('\nâœ… ØªØ³Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!'))
