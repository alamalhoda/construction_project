#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø² providerÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ ØºÛŒØ± Ø±Ø§ÛŒÚ¯Ø§Ù† Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import os
import sys
from dotenv import load_dotenv
from datetime import datetime
from typing import Dict, List, Tuple

# Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
load_dotenv()

# Ø±Ù†Ú¯â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    RESET = '\033[0m'
    BOLD = '\033[1m'

def print_header(text: str):
    """Ú†Ø§Ù¾ Ù‡Ø¯Ø± Ø¨Ø§ ÙØ±Ù…Øª Ø²ÛŒØ¨Ø§"""
    print(f"\n{Colors.BOLD}{Colors.BLUE}{'=' * 80}{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.BLUE}{text.center(80)}{Colors.RESET}")
    print(f"{Colors.BOLD}{Colors.BLUE}{'=' * 80}{Colors.RESET}\n")

def print_success(text: str):
    """Ú†Ø§Ù¾ Ù¾ÛŒØ§Ù… Ù…ÙˆÙÙ‚ÛŒØª"""
    print(f"{Colors.GREEN}âœ… {text}{Colors.RESET}")

def print_error(text: str):
    """Ú†Ø§Ù¾ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§"""
    print(f"{Colors.RED}âŒ {text}{Colors.RESET}")

def print_warning(text: str):
    """Ú†Ø§Ù¾ Ù¾ÛŒØ§Ù… Ù‡Ø´Ø¯Ø§Ø±"""
    print(f"{Colors.YELLOW}âš ï¸  {text}{Colors.RESET}")

def print_info(text: str):
    """Ú†Ø§Ù¾ Ø§Ø·Ù„Ø§Ø¹Ø§Øª"""
    print(f"{Colors.BLUE}â„¹ï¸  {text}{Colors.RESET}")

# Ù†ØªØ§ÛŒØ¬ ØªØ³Øª
results = {
    'google': {'free': [], 'paid': [], 'errors': []},
    'openai': {'free': [], 'paid': [], 'errors': []},
    'openrouter': {'free': [], 'paid': [], 'errors': []},
    'huggingface': {'free': [], 'paid': [], 'errors': []},
}

def test_google_gemini():
    """ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Google Gemini"""
    print_header("ğŸ” ØªØ³Øª Google Gemini")
    
    api_key = os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
    if not api_key:
        print_error("GOOGLE_API_KEY ÛŒØ§ GEMINI_API_KEY ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        results['google']['errors'].append("API key not found")
        return
    
    print_success(f"API Key found: {api_key[:20]}...")
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø­ØªÙ…Ø§Ù„ÛŒ
    free_models = [
        'gemini-2.0-flash',
        'gemini-2.0-flash-001',
        'gemini-2.5-flash',
        'gemini-flash-latest',
        'gemini-2.0-flash-lite',
        'gemini-2.0-flash-lite-001',
    ]
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ
    paid_models = [
        'gemini-2.5-pro',
        'gemini-2.0-pro-exp',
        'gemini-3-pro-preview',
    ]
    
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        
        # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†
        print_info("ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†...")
        for model_name in free_models:
            try:
                model = genai.GenerativeModel(model_name)
                response = model.generate_content("test")
                print_success(f"{model_name} - Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)")
                results['google']['free'].append(model_name)
            except Exception as e:
                error_msg = str(e)
                if 'quota' in error_msg.lower() or 'billing' in error_msg.lower():
                    print_warning(f"{model_name} - Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª")
                    results['google']['paid'].append(model_name)
                elif 'location' in error_msg.lower() or 'not supported' in error_msg.lower():
                    print_error(f"{model_name} - Ù…Ù†Ø·Ù‚Ù‡ Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ (ØªØ­Ø±ÛŒÙ…)")
                    results['google']['errors'].append(f"{model_name}: Location not supported")
                elif '404' in error_msg or 'not found' in error_msg.lower():
                    print_error(f"{model_name} - Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
                    results['google']['errors'].append(f"{model_name}: Not found")
                else:
                    print_error(f"{model_name} - Ø®Ø·Ø§: {error_msg[:100]}")
                    results['google']['errors'].append(f"{model_name}: {error_msg[:100]}")
        
        # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ
        print_info("ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ...")
        for model_name in paid_models:
            try:
                model = genai.GenerativeModel(model_name)
                response = model.generate_content("test")
                print_success(f"{model_name} - Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯")
                results['google']['paid'].append(model_name)
            except Exception as e:
                error_msg = str(e)
                if 'quota' in error_msg.lower() or 'billing' in error_msg.lower():
                    print_warning(f"{model_name} - Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª")
                    results['google']['paid'].append(f"{model_name} (needs payment)")
                else:
                    print_error(f"{model_name} - Ø®Ø·Ø§: {error_msg[:100]}")
                    results['google']['errors'].append(f"{model_name}: {error_msg[:100]}")
                    
    except ImportError:
        print_error("google-generativeai Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª! (pip install google-generativeai)")
        results['google']['errors'].append("Package not installed")
    except Exception as e:
        print_error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {str(e)}")
        results['google']['errors'].append(f"General error: {str(e)}")

def test_openai():
    """ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ OpenAI"""
    print_header("ğŸ” ØªØ³Øª OpenAI")
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print_error("OPENAI_API_KEY ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        results['openai']['errors'].append("API key not found")
        return
    
    print_success(f"API Key found: {api_key[:20]}...")
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø­ØªÙ…Ø§Ù„ÛŒ (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù‡Ù…Ù‡ Ù¾ÙˆÙ„ÛŒ Ù‡Ø³ØªÙ†Ø¯)
    free_models = []  # OpenAI Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ù†Ø¯Ø§Ø±Ø¯
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ
    paid_models = [
        'gpt-4o-mini',
        'gpt-4o',
        'gpt-4-turbo',
        'gpt-4',
        'gpt-3.5-turbo',
    ]
    
    try:
        from langchain_openai import ChatOpenAI
        
        # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ
        print_info("ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ OpenAI...")
        for model_name in paid_models:
            try:
                llm = ChatOpenAI(
                    model=model_name,
                    openai_api_key=api_key,
                    temperature=0,
                    max_tokens=10  # Ú©Ù… Ú©Ø±Ø¯Ù† tokens Ø¨Ø±Ø§ÛŒ ØªØ³Øª
                )
                response = llm.invoke("test")
                print_success(f"{model_name} - Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯")
                results['openai']['paid'].append(model_name)
            except Exception as e:
                error_msg = str(e)
                if 'quota' in error_msg.lower() or 'insufficient_quota' in error_msg.lower():
                    print_warning(f"{model_name} - quota ØªÙ…Ø§Ù… Ø´Ø¯Ù‡")
                    results['openai']['errors'].append(f"{model_name}: Quota exceeded")
                elif '401' in error_msg or 'auth' in error_msg.lower():
                    print_error(f"{model_name} - Ù…Ø´Ú©Ù„ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª")
                    results['openai']['errors'].append(f"{model_name}: Authentication error")
                elif '429' in error_msg:
                    print_warning(f"{model_name} - rate limit")
                    results['openai']['errors'].append(f"{model_name}: Rate limit")
                else:
                    print_error(f"{model_name} - Ø®Ø·Ø§: {error_msg[:100]}")
                    results['openai']['errors'].append(f"{model_name}: {error_msg[:100]}")
                    
    except ImportError:
        print_error("langchain-openai Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª! (pip install langchain-openai)")
        results['openai']['errors'].append("Package not installed")
    except Exception as e:
        print_error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {str(e)}")
        results['openai']['errors'].append(f"General error: {str(e)}")

def test_openrouter():
    """ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ OpenRouter"""
    print_header("ğŸ” ØªØ³Øª OpenRouter")
    
    api_key = os.getenv('OPENROUTER_API_KEY')
    if not api_key:
        print_error("OPENROUTER_API_KEY ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        results['openrouter']['errors'].append("API key not found")
        return
    
    print_success(f"API Key found: {api_key[:20]}...")
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†
    free_models = [
        'google/gemini-2.0-flash-exp:free',
        'z-ai/glm-4.5-air:free',
        'google/gemini-2.0-flash-exp:free',
    ]
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ
    paid_models = [
        'openai/gpt-4o-mini',
        'openai/gpt-4o',
        'anthropic/claude-3-sonnet',
    ]
    
    try:
        from langchain_openai import ChatOpenAI
        
        # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†
        print_info("ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†...")
        for model_name in free_models:
            try:
                llm = ChatOpenAI(
                    model=model_name,
                    openai_api_key=api_key,
                    base_url="https://openrouter.ai/api/v1",
                    temperature=0,
                    max_tokens=10
                )
                response = llm.invoke("test")
                print_success(f"{model_name} - Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)")
                results['openrouter']['free'].append(model_name)
            except Exception as e:
                error_msg = str(e)
                if '429' in error_msg or 'rate limit' in error_msg.lower():
                    print_warning(f"{model_name} - rate limit (Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø±ÙˆØ²Ø§Ù†Ù‡)")
                    results['openrouter']['errors'].append(f"{model_name}: Rate limit")
                elif '402' in error_msg or 'credit' in error_msg.lower():
                    print_warning(f"{model_name} - Ù†ÛŒØ§Ø² Ø¨Ù‡ credit")
                    results['openrouter']['paid'].append(model_name)
                elif '401' in error_msg or 'auth' in error_msg.lower():
                    print_error(f"{model_name} - Ù…Ø´Ú©Ù„ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª")
                    results['openrouter']['errors'].append(f"{model_name}: Authentication error")
                else:
                    print_error(f"{model_name} - Ø®Ø·Ø§: {error_msg[:100]}")
                    results['openrouter']['errors'].append(f"{model_name}: {error_msg[:100]}")
        
        # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ
        print_info("ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ...")
        for model_name in paid_models:
            try:
                llm = ChatOpenAI(
                    model=model_name,
                    openai_api_key=api_key,
                    base_url="https://openrouter.ai/api/v1",
                    temperature=0,
                    max_tokens=10
                )
                response = llm.invoke("test")
                print_success(f"{model_name} - Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯")
                results['openrouter']['paid'].append(model_name)
            except Exception as e:
                error_msg = str(e)
                if '402' in error_msg or 'credit' in error_msg.lower():
                    print_warning(f"{model_name} - Ù†ÛŒØ§Ø² Ø¨Ù‡ credit")
                    results['openrouter']['paid'].append(f"{model_name} (needs credit)")
                else:
                    print_error(f"{model_name} - Ø®Ø·Ø§: {error_msg[:100]}")
                    results['openrouter']['errors'].append(f"{model_name}: {error_msg[:100]}")
                    
    except ImportError:
        print_error("langchain-openai Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª! (pip install langchain-openai)")
        results['openrouter']['errors'].append("Package not installed")
    except Exception as e:
        print_error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {str(e)}")
        results['openrouter']['errors'].append(f"General error: {str(e)}")

def test_huggingface():
    """ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face"""
    print_header("ğŸ” ØªØ³Øª Hugging Face")
    
    api_key = os.getenv('HUGGINGFACE_API_KEY')
    endpoint = os.getenv('HUGGINGFACE_ENDPOINT')
    model_id = os.getenv('HUGGINGFACE_MODEL_ID', 'mistralai/Mistral-7B-Instruct-v0.2')
    
    if not api_key and not endpoint:
        print_warning("HUGGINGFACE_API_KEY ÛŒØ§ HUGGINGFACE_ENDPOINT ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        print_info("Hugging Face Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª Ø§Ù…Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù†ØµØ¨ sentence-transformers Ø¯Ø§Ø±Ø¯")
        results['huggingface']['errors'].append("API key/endpoint not found")
        return
    
    if api_key:
        print_success(f"API Key found: {api_key[:20]}...")
    if endpoint:
        print_success(f"Endpoint found: {endpoint}")
    
    try:
        from langchain_huggingface import HuggingFaceEndpoint
        
        # ØªØ³Øª Ø¨Ø§ endpoint
        if endpoint:
            try:
                llm = HuggingFaceEndpoint(
                    endpoint_url=endpoint,
                    huggingfacehub_api_token=api_key,
                    temperature=0,
                    max_new_tokens=10
                )
                response = llm.invoke("test")
                print_success(f"Endpoint {endpoint} - Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)")
                results['huggingface']['free'].append(f"Endpoint: {endpoint}")
            except Exception as e:
                error_msg = str(e)
                print_error(f"Endpoint - Ø®Ø·Ø§: {error_msg[:100]}")
                results['huggingface']['errors'].append(f"Endpoint: {error_msg[:100]}")
        
        # ØªØ³Øª Ø¨Ø§ model_id
        if model_id:
            try:
                llm = HuggingFaceEndpoint(
                    repo_id=model_id,
                    huggingfacehub_api_token=api_key,
                    temperature=0,
                    max_new_tokens=10
                )
                response = llm.invoke("test")
                print_success(f"Model {model_id} - Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†)")
                results['huggingface']['free'].append(f"Model: {model_id}")
            except Exception as e:
                error_msg = str(e)
                print_error(f"Model {model_id} - Ø®Ø·Ø§: {error_msg[:100]}")
                results['huggingface']['errors'].append(f"{model_id}: {error_msg[:100]}")
                
    except ImportError:
        print_error("langchain-huggingface Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª! (pip install langchain-huggingface)")
        print_info("ÛŒØ§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² sentence-transformers Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø­Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
        results['huggingface']['errors'].append("Package not installed")
    except Exception as e:
        print_error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {str(e)}")
        results['huggingface']['errors'].append(f"General error: {str(e)}")

def print_summary():
    """Ú†Ø§Ù¾ Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬"""
    print_header("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬")
    
    for provider, data in results.items():
        provider_name = provider.upper()
        print(f"\n{Colors.BOLD}{provider_name}:{Colors.RESET}")
        
        if data['free']:
            print(f"  {Colors.GREEN}âœ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ú©Ø§Ø±Ø¢Ù…Ø¯ ({len(data['free'])}):{Colors.RESET}")
            for model in data['free']:
                print(f"    â€¢ {model}")
        
        if data['paid']:
            print(f"  {Colors.YELLOW}ğŸ’° Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆÙ„ÛŒ ({len(data['paid'])}):{Colors.RESET}")
            for model in data['paid']:
                print(f"    â€¢ {model}")
        
        if data['errors']:
            print(f"  {Colors.RED}âŒ Ø®Ø·Ø§Ù‡Ø§ ({len(data['errors'])}):{Colors.RESET}")
            for error in data['errors']:
                print(f"    â€¢ {error}")
        
        if not data['free'] and not data['paid'] and not data['errors']:
            print(f"  {Colors.YELLOW}âš ï¸  ØªØ³Øª Ù†Ø´Ø¯Ù‡{Colors.RESET}")
    
    # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
    print(f"\n{Colors.BOLD}{Colors.BLUE}ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:{Colors.RESET}")
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† Ú¯Ø²ÛŒÙ†Ù‡
    best_options = []
    for provider, data in results.items():
        if data['free']:
            best_options.append((provider, data['free'][0]))
    
    if best_options:
        print(f"\n  {Colors.GREEN}âœ… Ø¨Ù‡ØªØ±ÛŒÙ† Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†:{Colors.RESET}")
        for provider, model in best_options:
            print(f"    â€¢ {provider.upper()}: {model}")
    else:
        print(f"\n  {Colors.YELLOW}âš ï¸  Ù‡ÛŒÚ† Ù…Ø¯Ù„ Ø±Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ú©Ø§Ø± Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯!{Colors.RESET}")
        print(f"  {Colors.YELLOW}   Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ VPN Ø¨Ø§Ø´Ø¯ ÛŒØ§ API key Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª{Colors.RESET}")

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print_header("ğŸ§ª ØªØ³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù")
    print(f"Ø²Ù…Ø§Ù† ØªØ³Øª: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ØªØ³Øª Google Gemini
    test_google_gemini()
    
    # ØªØ³Øª OpenAI
    test_openai()
    
    # ØªØ³Øª OpenRouter
    test_openrouter()
    
    # ØªØ³Øª Hugging Face
    test_huggingface()
    
    # Ú†Ø§Ù¾ Ø®Ù„Ø§ØµÙ‡
    print_summary()
    
    print_header("âœ… ØªØ³Øª Ú©Ø§Ù…Ù„ Ø´Ø¯!")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ØªØ³Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯!")
        sys.exit(1)
    except Exception as e:
        print_error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

